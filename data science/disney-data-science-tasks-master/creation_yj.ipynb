{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4 import element\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d5003",
   "metadata": {},
   "source": [
    "### Task #1: get info box for Toy Story 3 film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8dbfef",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(\"https://en.wikipedia.org/wiki/Toy_Story_3\")\n",
    "\n",
    "# Convert to a beautiful soup object\n",
    "# soup = bs(r.content)\n",
    "\n",
    "# Print out the HTML\n",
    "# contents = soup.prettify()\n",
    "# print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb1461",
   "metadata": {},
   "source": [
    "### load_info_box function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd49e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_info_box(contents):\n",
    "    soup = bs(r.content)\n",
    "    # info_rows = soup.find(class_=[\"infobox vevent\", \"infobox vcard\"])\n",
    "    info_rows = soup.find(class_=\"infobox\")\n",
    "    \n",
    "    if info_rows: \n",
    "        info_rows = info_rows.find_all(\"tr\")\n",
    "    else:\n",
    "        print (\"no class 'infobox vevent' \")\n",
    "        return -1\n",
    "    # c = info_box.prettify()\n",
    "    # info_rows = info_box.\n",
    "    film_info = {}\n",
    "    for i,row in enumerate(info_rows):\n",
    "        if i == 0: \n",
    "            film_info['Film Name'] = row.get_text()\n",
    "        elif i == 1: continue   #skip\n",
    "        #     # film_info[row.find(class_='infobox-label').get_text()] = row.find(class_= 'infobox-data').get_text()\n",
    "        # # elif i in range (2,19):  \n",
    "        else:  \n",
    "        #     # print (row.prettify())\n",
    "            try:\n",
    "                header= row.find(\"th\").get_text() if row.find(\"th\") else \"\"\n",
    "                data= row.find(\"td\").get_text() if row.find(\"td\") else \"\"\n",
    "            except:\n",
    "                print (\"not found: \", header,  i)\n",
    "            if header == '': continue\n",
    "            x = row.find(\"td\")\n",
    "            if not x:   # no table data\n",
    "                data = ''\n",
    "            else:\n",
    "                x_array = x.find_all('li')  \n",
    "                if not x_array: # no li, one item\n",
    "                    data  = x.get_text(\" \", strip=True).replace(\"\\xa0\", \" \") \n",
    "                else:   # one item\n",
    "                    data = [r.get_text(\" \", strip=True).replace(\"\\xa0\", \" \") for r in x_array]\n",
    "            film_info[header] = data\n",
    "            # print (i, header, \":\", data)\n",
    "    return film_info\n",
    "\n",
    "    # print (film_info)\n",
    "# film_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091526d",
   "metadata": {},
   "source": [
    "## Task #2: Get info box for all movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d6dd99",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e66bd8c",
   "metadata": {},
   "source": [
    "### just test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de201df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbls = soup.find('h3')\n",
    "# print (tbls)\n",
    "# # tbls = soup.select(['h3,'table.wikitable.sortable'])\n",
    "# tbl = tbls[1]\n",
    "# print (tbl.i)\n",
    "# for i in range(1,5):\n",
    "#         # tbls = tbls.next_element\n",
    "# #         tbls = tbls.next_sibling\n",
    "#         print (i,'-',tbls)\n",
    "# tbls = soup.select('table.wikitable.sortable')\n",
    "# tbls = soup.select('table.wikitable.sortable')\n",
    "# tbl = tbls[1]\n",
    "# print (repr(tbl))\n",
    "# i = 1\n",
    "# # tbls = soup.select(['h3','table.wikitable.sortable'])\n",
    "# tbls = soup.find_all('table', class_= 'wikitable sortable')\n",
    "# for s in tbls:\n",
    "#         print (i, '-', repr(s))\n",
    "#         i +=1\n",
    "#         # tbls = tbls.next_element\n",
    "#         # tbl = tbl.prev_sibling\n",
    "#         # if tbl:\n",
    "#         #         print (i,'-',tbl['class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddb5d09",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccd8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films\")\n",
    "\n",
    "\n",
    "# Convert to a beautiful soup object\n",
    "soup = bs(r.content)\n",
    "\n",
    "# soup.find_all('td', limit=5) #.find_all('td')\n",
    "base_url = 'https://en.wikipedia.org'\n",
    "flog = open('./out/log.txt', 'wt')\n",
    "movie_info = []\n",
    "for i,tbl in enumerate(soup.select('table.wikitable.sortable'), start=1):\n",
    "    # if i == 4: break\n",
    "    # print (tbl.prev_element)\n",
    "    # print (tbl.)\n",
    "    lnks = tbl.select('tbody td i a')\n",
    "    # print (lnks)\n",
    "    for j,lnk in enumerate (lnks,start=1):\n",
    "    #     # if j == 3: break\n",
    "        url = base_url + lnk['href']\n",
    "\n",
    "        # r = requests.get(base_url + lnk['href'])\n",
    "        print (f\"table: {i}, row: {j}, {lnk['title']}, {url}\")\n",
    "        flog.write(f\"table: {i}, row: {j}: {lnk['title']}, '----->', url\\n\")\n",
    "        # a_movie_data = load_info_box(r.content)\n",
    "        # if a_movie_data == -1:\n",
    "        #     flog.write (lnk['href'] + \"--class 'infobox vevent' not found\\n\")\n",
    "        #     continue\n",
    "        # elif a_movie_data == -2:\n",
    "        #     flog.write (lnk['href'] + \"--class 'iinfobox-data' not found\\n\")\n",
    "        #     continue\n",
    "        # elif a_movie_data == None:\n",
    "        #     flog.write (lnk['href'] + \"**load_info_box returns None \\n\")\n",
    "        #     continue\n",
    "        # movie_info.append(a_movie_data)\n",
    "        # with open('mycsvfile.csv', 'a') as f:  # append\n",
    "        #     w = csv.DictWriter(f, a_movie_data.keys())\n",
    "        #     w.writeheader()\n",
    "        #     w.writerow(a_movie_data)\n",
    "flog.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e797e",
   "metadata": {},
   "source": [
    "### work online/offline for the main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work online\n",
    "# r = requests.get(\"https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films\")\n",
    "\n",
    "# with open('./out/List_of_Walt_Disney_Pictures_films.html', 'wb') as f:\n",
    "#     f.write(r.content)\n",
    "\n",
    "# work offline\n",
    "with open('./out/List_of_Walt_Disney_Pictures_films.html', 'rb') as f:\n",
    "    soup = bs(f.read())\n",
    "\n",
    "# soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56bab52",
   "metadata": {},
   "source": [
    "### Main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info = []\n",
    "base_url = 'https://en.wikipedia.org'\n",
    "flog = open('./out/log.txt', 'wt')\n",
    "for i,tbl_h in enumerate(soup.select('h3'), start=1):\n",
    "    # print (tbl_h)\n",
    "    if i > 10: break    # last table is is 2020s table, rest are not in standard format\n",
    "    if tbl_h.string:\n",
    "        # if i > 1: break    #x table for testing, comment when done\n",
    "        table_header = tbl_h.string\n",
    "        print (i, 'Table:', table_header)\n",
    "        # print (tbl_h.nextSibling) # empty\n",
    "        tbl = tbl_h.nextSibling.nextSibling\n",
    "        \n",
    "        if tbl.name != 'table':\n",
    "            continue\n",
    "        # print ('tbl type:', type(tbl), tbl.tag, len(tbl) , tbl.keys, tbl.value, tbl.name)\n",
    "        for j, row in enumerate(tbl.find_all(name='tr'), start=1):\n",
    "            movie_data = row.select('td:nth-of-type(2)')    # end column\n",
    "            \n",
    "            if not movie_data:\n",
    "                continue\n",
    "\n",
    "            # print (movie_data)\n",
    "            try:\n",
    "                a_tag = movie_data[0].find('a')\n",
    "                movie_name = a_tag['title']\n",
    "                movie_link = base_url + a_tag['href']\n",
    "\n",
    "            except Exception as e:\n",
    "                # print (f\"{i}, {j}: *** Error parsing record: {e}, table: {table_header}, row #: {j}\")\n",
    "                    \n",
    "                print (f\"error: {e} : {table_header}, row: {j}\")\n",
    "                movie_name = movie_data[0].get_text(strip=True)\n",
    "                movie_link = None\n",
    "\n",
    "            \n",
    "            print (i, ',', j, \":\", table_header, movie_name, movie_link)\n",
    "            if not movie_link: \n",
    "                flog.write(f\"{i},{j}:, {table_header}, {movie_name}, No details \\n\")\n",
    "                continue\n",
    "            r = requests.get(movie_link)\n",
    "            flog.write(f\"{i},{j}:, {table_header}, {movie_name}, {movie_link}\\n\")\n",
    "            a_movie_data = load_info_box(r.content)\n",
    "            if a_movie_data == -1:\n",
    "                flog.write (movie_link + \"--class 'infobox vevent' not found\\n\")\n",
    "                continue\n",
    "            elif a_movie_data == -2:\n",
    "                flog.write (movie_link + \"--class 'infobox-data' not found\\n\")\n",
    "                continue\n",
    "            elif a_movie_data == None:\n",
    "                flog.write (movie_link + \"**load_info_box returns None \\n\")\n",
    "                continue\n",
    "\n",
    "            # print (i, 'Table:', table_header)\n",
    "            \n",
    "            full_movie_data = {'table': table_header, 'tbl#':i, \"row#\": j}\n",
    "            full_movie_data.update(a_movie_data)\n",
    "            movie_info.append(full_movie_data)\n",
    "\n",
    "flog.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e688dfd",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# r = requests.get(\"https://en.wikipedia.org/wiki/Zorro_(1957_TV_series)#Theatrical\")\n",
    "# a_movie_data = load_info_box(r.content)\n",
    "# print (a_movie_data)\n",
    "len(movie_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d89b0",
   "metadata": {},
   "source": [
    "### Write result DataFrame into csv file for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = []\n",
    "for i,row in enumerate(movie_info):\n",
    "    print \n",
    "    for key, val in row.items():\n",
    "        if key not in header: \n",
    "            header.append(key)\n",
    "\n",
    "\n",
    "with open('./out/mycsvfile-2.csv', 'w', encoding='utf8') as f:  \n",
    "    w = csv.DictWriter(f, header)\n",
    "    w.writeheader()\n",
    "    for i, r in enumerate(movie_info):\n",
    "        try:\n",
    "            w.writerow(r)\n",
    "        except Exception as e:\n",
    "            print(i, e, r)\n",
    "            # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_data(file_name, data):\n",
    "    with open(file_name, \"w\", encoding  = \"utf-8\") as fp:\n",
    "        json.dump(movie_info, fp, ensure_ascii = False)\n",
    "\n",
    "def load_data(file_name, data):\n",
    "    with open(file_name, \"w\", encoding  = \"utf-8\") as fp:\n",
    "        return json.load(fp)\n",
    "\n",
    "save_data(\"./out/movies.json\", movie_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
